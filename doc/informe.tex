\documentclass[11pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{graphicx}
\usepackage{fancyvrb}
\usepackage{color}
\addtolength{\textwidth}{2cm}
\addtolength{\marginparwidth}{-10cm}
\addtolength{\oddsidemargin}{-1cm}

\addtolength{\textwidth}{3cm}
\addtolength{\hoffset}{-1.5cm}
\addtolength{\textheight}{2cm}
\addtolength{\voffset}{-0.5cm}

% Inserts an horizontal line.
\newcommand{\Hrule}{\rule{\linewidth}{0.6mm}}

\fvset{frame=single}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}


% Portada.

\begin{titlepage}

\begin{center}

\Hrule \\[0.4cm]
{\Huge \bfseries Proxy HTTP 1.1}\\[0.3cm]
\LARGE{Informe de desarrollo}
\Hrule \\[0.4cm]

\end{center}

\vfill

\begin{center}

\Large{Matías Ezequiel Colotto\\}
\Large{María Eugenia Cura\\}
\Large{Santiago José Samra\\}
\Large{Jorge Ezequiel Scaruli\\}
\vspace{3cm}

\large{Protocolos de Comunicación}\\
\large{2010}

\end{center}

\end{titlepage}


% Documento

\tableofcontents

\clearpage

\section{Introducción}

Se propuso como Trabajo Práctico Especial de la materia Protocolos de
Comunicación el desarrollo de un servidor proxy para el protocolo \textit{HTTP
(Hypertext transfer protocol)} en su versión 1.1, que pueda ser utilizado
para navegar en Internet y que sea compatible con los navegadores
\textit{Mozilla Firefox}, \textit{Google Chrome} e \textit{Internet Explorer}.\\

El objetivo de este informe es dar a conocer las funcionalidades implementadas y
describir el desarrollo de las mismas. Además, se presentan pruebas de carga
realizadas al servidor, así como posibles extensiones de la implementación.

\clearpage


\section{Protocolos desarrollados}

El proyecto se realizó completa y únicamente sobre el protocolo \textit{HTTP}
1.1 especificado por la RFC 2616\footnote{http://tools.ietf.org/html/rfc2616}. Por
lo tanto, no se desarrollaron ni implementaron protocolos propios.\\

El servidor ofrece la posibilidad de ser configurado y monitoreado remotamente
y, aunque esto pudo haber sido implementado mediante protocolos propios, se
decidió que no sea así. Una de las razones de ello fue la posibilidad
de utilizar un protocolo ya existente como \textit{HTTP}, con lo que se evitó la
dificultad de diseñar uno propio teniendo en cuenta las dificultades que
implica. Otra razón fue el hecho de que, al usar \textit{HTTP}, es posible
ofrecer usabilidad web para estos servicios. Finalmente, el hecho de poder
aprovechar las características de parseo de los \textit{requests HTTP}, que
fueron desarrolladas para el funcionamiento del \emph{proxy}, hizo que
implementar el monitoreo y la configuración sea relativamente simple.

\clearpage


\section{Problemas encontrados}

Durante el desarrollo se encontraron gran cantidad de problemas, que debieron
ser solucionados para lograr un producto sólido. Se mencionan a continuación
algunos de ellos:

\subsection{Decisión sobre el uso de \textit{threads} o E/S asincrónica}

En un principio, para ponerse en contacto con las funcionalidades que ofrece
Java para programar servidores concurrentes y manejo de \textit{threads}, se
procedió a implementar pequeños servidores que ofrezcan servicios básicos (como
por ejemplo, \textit{echo}). Estas implementaciones se hicieron utilizando
las dos alternativas analizadas en la materia:

\begin{enumerate}
  \item Teniendo un servidor que, por cada pedido de un cliente, lance un nuevo
  \textit{thread} que lo atienda.
  \item Mediante entrada/salida asincrónica (utilizando el mecanismo
  \textit{select}), en el cual los pedidos entrantes de los clientes se
  mantienen inactivos hasta que el servidor los tome y los atienda.
\end{enumerate}

Analizando el funcionamiento de cada una de las dos alternativas, se observó que
la primera tenía un funcionamiento más acorde a lo que se esperaba del servidor
ya que, básicamente, la segunda opción tenía un modo de trabajar iterativo, lo
que impedía la concurrencia del proxy.\\

Sin embargo, se pensó en una tercera alternativa que consistía en una
combinación de las dos anteriormente mencionadas. Consistía en que el servidor
conste de dos \textit{threads}. El primero aceptaba pedidos de clientes y los
colocaba en una cola, y el segundo utilizaba el mecanismo de entrada/salida
asincrónica para atender las conexiones que estaban en dicha cola. Con esto, se
lograba un funcionamiento no iterativo del mecanismo \textit{select}, porque no
era necesario que el servidor esté desocupado para atender una conexión
entrante; asimismo, se evitaba el lanzamiento de un nuevo \textit{thread} por
cada conexión, algo que implicaba un gran consumo de memoria y procesamiento.\\

No obstante, la tercera opción no fue llevada a la práctica, debido a que se
intentó programar un servidor \textit{echo} implementándola y se observó que el
funcionamiento ideal implicaba un gran control de sincronización entre los
\textit{threads}, algo que difícilmente fue logrado en el servidor \textit{echo}
luego de muchos intentos. Por lo tanto, intentar aplicarlo en el proxy llevaría
a grandes complicaciones.\\

Finalmente, se decidió implementar una variante de la primera opción mencionada,
en la cual en vez de disparar un nuevo \textit{thread} por cada pedido de un
cliente, se tome uno entre varios disponibles de un \textit{pool}. De esta
manera, se limitó la cantidad de \textit{threads} existentes al mismo tiempo en
el servidor. Aunque esta limitación implica una menor cantidad de
\textit{threads} funcionando simultáneamente en el servidor, hace que el consumo
de memoria sea moderado y que no se requiera tanta capacidad de procesamiento.
De todos modos, la cantidad de \textit{threads} presentes en el \textit{pool}
puede ser configurada mediante el archivo de configuración del proxy,
con lo cual estas limitaciones pueden aplicarse en función de las
características de la máquina que sirva el proxy y así aprovecharlas para un
funcionamiento óptimo.

\clearpage


\subsection{Interpretación y parseo de mensajes \textit{HTTP}}

Luego de la decisión tomada acerca de cómo atender clientes, se llevó a cabo el
parseo de mensajes \textit{HTTP}.\\

Antes de diseñar los \textit{parsers}, se pensó una jerarquía de clases que
modele los paquetes \textit{HTTP}.\footnote{Puede encontrarse en el paquete
\textbf{org.cssc.prototpe.http}} A grandes rasgos, consistió en una clase
padre \verb+HttpPacket+ de la cual heredan \verb+HttpRequest+ y
\verb+HttpResponse+, y que contienen un método
(\verb+GET+, \verb+POST+ o \verb+HEAD+, si se trata de un
\textit{request}), un \textit{status code} (si se trata de un
\textit{response}) y un \textit{header} con entradas campo-valor. En un
principio se pensó en que las clases tengan también un \textit{body}
asociado, ya que tanto los
\textit{requests} como los \textit{responses} podrían ocasionalmente tener un
cuerpo. Sin embargo esto no se realizó, y la razón es mencionada
luego.\\

Utilizando la herramienta
\textit{jFlex}\footnote{http://jflex.de/}, se programaron los parsers que, en
base al \verb+InputStream+ de un \textit{socket}, construyan el
\verb+HttpRequest+ o \verb+HttpResponse+ correspondiente. En este punto fue
cuando se notó que incluir el cuerpo del mensaje dentro de esas clases no era conveniente,
debido a que ello implicaba parsearlo por completo y asociárselo a la clase, y
no se tenían en cuenta los siguiente factores:
\begin{enumerate}
  \item Es conveniente devolverle al cliente la información del cuerpo dividida
  en partes, para que el navegador pueda construir lo que dicha información
  represente a medida que le va llegando, y no que tenga la obligación de
  recibir todo el cuerpo para recién visualizar el contenido.
  \item El mensaje puede tener el campo \verb+Transfer-encoding: chunked+, con
  lo cual, si se parsea todo el contenido del cuerpo y una vez hecho esto se lo
  envía, se pierde la funcionalidad que un paquete \verb+chunked+ ofrece (por
  ejemplo, la generación de páginas dinámicas).
\end{enumerate}
Por lo tanto, se decidió que los parsers tengan métodos para leer el paquete sin
cuerpo, y otros para leer el próximo \verb+chunk+ del cuerpo si el contenido es
\verb+chunked+, o leer los próximos \textit{n} bytes del mismo si no lo es.

\subsection{Compatibilidad con HTTP 1.0}

Si bien el proxy funciona con el protocolo \textit{HTTP} en su versión 1.1, debe
ser compatible hacia atrás con la versión 1.0.\\

En principio no se encontraron grandes dificultades, debido a que se testeaba
con sitios que devolvían \textit{responses} versión 1.1. Sin embargo, al probar
con el proxy transparente utilizado en el ITBA, se descubrió que el
funcionamiento no era del todo correcto.\\

En primera medida, el proxy transparente utilizado en el ITBA suele cerrar las
conexiones sin avisar. Esto generó problemas en el manejador de conexiones, que
suponía que si una respuesta no aparecía con el header \verb+Connection: close+,
no debía cerrar la conexión ya que ésta se mantendría viva (siguiendo el
estándar \textit{HTTP 1.1}).\\

Otro problema que surgió fue el hecho de que el servidor no manejaba respuestas
\emph{chunked}. Se presentó la problemática de que el proxy implementado no
funcionaba del todo bien con sitios que devolvían respuestas \emph{chunked},
pero dichas páginas funcionaban sin problema al testear desde el ITBA.\\

Si bien podrían pensarse como problemas menores, el hecho de que el
comportamiento del proxy en el ITBA difiera del comportamiento del mismo proxy
en otro lugar generó confusión y dificultó la solución de otros problemas, que
por estos motivos no se podían encontrar.\\

\textbf{\color{red}{\large{Agregar acá una descripción del problema que se
tenía al usar el proxy del ITBA, y mencionar cuál fue la solución.}}}

\subsection{Conexiones persistentes}

Una de las funcionalidades requeridas para el proxy fue la de implementar
conexiones persistentes; es decir, que no se cree una nueva conexión con el
servidor \textit{origin} cada vez que se hace un \textit{request}, sino mantener
abiertas las conexiones. De esta manera, ante un \textit{request} a un servidor
con una conexión ya abierta, se evita tener que abrir uno nuevo.\\

En principio, se mantenía abierta una conexión para cada servidor
\textit{origin}. Pero esto generaba un funcionamiento ineficiente, ya que no
podían haber dos conexiones al mismo servidor simultáneamente, con lo cual las conexiones
persistentes reducían la capacidad del proxy. Por lo tanto, se optó por tener,
para un mismo servidor \textit{origin}, $n$ conexiones (donde $n$
es configurable), y tener un máximo de $m$ conexiones abiertas.\\

La implementación realizada se basa en semáforos.\footnote{Ver la clase
\textbf{org.cssc.prototpe.PersistentSemaphorizedServerManager}} Existe primero
un semáforo que se inicializa con $m$ permisos. Al solicitarle una conexión a 
un servidor al \verb+ServerManager+, se pide un permiso de dicho semáforo; al
liberarse una conexión, se libera un permiso del mismo semáforo. De manera
similar, para cada servidor, existe un semáforo inicializado con $n$ permisos;
cuando se desea obtener una conexión para dicho servidor, se solicita un permiso
al semáforo correspondiente a ese servidor, y cuando se libera una conexión
a dicho servidor, se libera un permiso.\\

Para determinar si se debe crear una
nueva conexión o no, lo que se hace es guardarse por cada servidor una cola de
\textit{sockets} abiertos: una vez adquirido el permiso del semáforo
correspondiente al servidor, se fija si esta cola está vacía. Si no lo está,
entonces significa que hay un \textit{socket} abierto a ese servidor, listo para
ser usado; si está vacía, entonces se tiene permiso para crear una nueva
conexión, ya que se pudo entrar al semáforo del servidor. Cuando se libera un
\textit{socket}, si no está cerrado, se agrega a la cola de conexiones 
persistentes para el servidor correspondiente: de esta manera, se reusan los
\textit{sockets}.\\

Como hay un máximo de $m$ conexiones persistentes abiertas al mismo tiempo,
independiente de cuál sea su servidor, se implementó, lógicamente, un mecanismo
para cerrarlas. En las colas de conexiones de cada servidor aparecen solamente
\textit{sockets} que no están en uso. Por lo tanto, cuando se necesita crear un
nuevo \textit{socket}, si se excede la capacidad de conexiones persistentes, se
busca aquel servidor del que no se hayan pedido conexiones hace
más tiempo, y se libera un socket que aparezca en dicha cola (o, en su defecto,
se sigue buscando una cola que tenga conexiones abiertas). Esta conexión seguro
existe debido a la existencia del semáforo con $m$ permisos: este semáforo se
asegura de que, en cualquier momento, haya como máximo $m$ threads hablando con
algún servidor. Como el thread actual no ha obtenido aún una conexión, hay en
ese momento $m - 1$ threads como máximo hablando con algún servidor; como hay
$m$ conexiones ya abiertas, hay al menos una que no está siendo usada.\\

Paralelamente a los problemas de velocidad, aparecieron también otros, 
más serios, entre los cuales se pueden mencionar:

\begin{itemize}
  \item El encargado de mantener conexiones persistentes con los servidores,
  después de un tiempo, dejaba de otorgar conexiones y dejaba a los threads
  bloqueados. Esto se debía a que no se estaba liberando siempre el socket
  correspondiente a la conexión con el servidor.
  \item Las conexiones con los clientes nunca se cerraban, y el proxy
  simplemente se quedaba leyendo de las mismas. Se debió implementar un timeout
  en dicha lectura, y hacer que se cierren las conexiones cuando se supere ese
  timeout.
  \item Se recibían \emph{responses} sucios cuando se reusaba una conexión a un
  servidor. Esto ocurría debido a que no se leía correctamente la respuesta
  anterior, con lo que quedaban bytes pertenecientes a la misma; al intentar
  leer la nueva \emph{response} del siguiente \emph{request}, se leían dichos
  bytes, generando un error.
\end{itemize}

En síntesis, la implementación de conexiones persistentes tanto entre el cliente
y el proxy como entre el proxy y los servidores \textit{origin} fue la principal
causa de problemas en el desarrollo del trabajo práctico, y su solución nunca
fue simple, debido a que por la naturaleza del servidor y la existencia de
threads concurrentes, resultaba complicado reproducir los bugs.

\subsection{Configuración remota}

Debido a las características de la implementación, hay ciertos parámetros que no
son configurables remotamente y sólo pueden ser cambiados
directamente desde el XML de configuración y reiniciando el proxy. Entre ellos,
por ejemplo, se encuentra la cantidad de threads que hay en el \emph{pool}, o la
cantidad máxima de conexiones persistentes.\\

\textbf{\color{red}{\large{Agregar info.}}}

\subsection{Proxy transparente}

\textbf{\color{red}{\large{Describir una vez que lo testeemos.}}}

\clearpage


% \section{Más funcionalidades}
% 
% A continuación se describen más funcionalidades del proxy, en cuyas
% implementaciones no se tuvieron problemas mayores.
% 
% \textbf{\color{red}{\large{Si alguna de las cosas que está acá trajo
% problemas, tiene que moverse a la sección anterior.}}}
% 
% \subsection{Encadenamiento de proxies}
% 
% El proxy admite funcionar redirigiendo sus requests hacia otro proxy.
% 
% \textbf{\color{red}{\large{Seguir con la descripción de esta funcionalidad.}}}
% 
% \clearpage


\section{Limitaciones}

El proxy desarrollado tiene las siguientes limitaciones:

\begin{itemize}
  \item No soporta \emph{pipelining} de requests al servidor. Por ello, si bien
  se reusan las conexiones a los servidores cuando llegan distintos requests, la
  eficiencia de ello deja que desear.
  \item El número de conexiones simultáneas a un servidor \textit{origin} está
  limitado, debido a la implementación de conexiones persistentes.
  \item No soporta todos los métodos \textit{HTTP}, solo \verb+GET+, \verb+HEAD+
  y \verb+POST+; con lo cual hay ciertas páginas que no funcionan del todo
  bien porque usan otros métodos.
  \item Para realizar filtrado de páginas por \textit{Content-length}, es
  necesario parsear el contenido completo de un paquete. Por lo tanto, no se le
  puede enviar la información de a pedazos al cliente en el caso de que no haya
  un header \emph{content-length}: se debe leer todo el contenido y luego enviar
  la información, con lo cual se pierde en eficiencia.
\end{itemize}

\section{Posibles extensiones}

\section{Conclusión}

\textbf{\color{red}{\large{Nunca en tu vida tenés que hacer un proxy HTTP.
Usa uno ya hecho.}}}

\section{Ejemplos de testeo}

\section{Guía de instalación}

\section{Guía de configuración}

\section{Ejemplos de configuración}

\section{Documento de diseño}

\end{document}